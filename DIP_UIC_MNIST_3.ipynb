{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+rMge7lYkmry88Y1g6pwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhmd2015/ImageProcessing1UIC/blob/main/DIP_UIC_MNIST_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install idx2numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QtRULv9f_Dt",
        "outputId": "f2878f78-c06d-4478-a3ea-56282cfb7433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=ee60fda678b581b9648a2e81c35c7d05563eaa36f7dafcf39d42bea9d35d5104\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/f4/e7/643fc5f932ec2ff92997f43f007660feb23f948aa8486f1107\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "uQ7KEYEyf2iu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import idx2numpy\n",
        "\n",
        "def load_data(images_path, labels_path):\n",
        "    images = idx2numpy.convert_from_file(images_path)\n",
        "    labels = idx2numpy.convert_from_file(labels_path)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "eEWJYI6hgQ2F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_images, train_labels = load_data('train-images-idx3-ubyte', 'train-labels-idx1-ubyte')\n",
        "\n",
        "# test_images, test_labels = load_data('t10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte')"
      ],
      "metadata": {
        "id": "gzF6nZmtiLdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images.reshape((60000, -1)).astype('float32') / 255  # Flatten and normalize"
      ],
      "metadata": {
        "id": "FNUMaucyiMTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX6DXwjYfvg6",
        "outputId": "fb92aa58-fbf9-4b1d-ef6a-21cf0385bedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/mixture/_base.py:119: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.11\n",
            "Testing accuracy: 0.11\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (b) Split data and thresholding\n",
        "# Using all 60000 for training and 10000 for testing as specified in the problem\n",
        "train_images = np.where(train_images > 128, 1, 0)\n",
        "test_images = np.where(test_images > 128, 1, 0)\n",
        "\n",
        "# Flatten the images for the GMM\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "\n",
        "# (c) Model each class using GMM\n",
        "gmm_classifiers = {}\n",
        "for label in range(10):\n",
        "    data = train_images[train_labels == label]\n",
        "    gmm = GaussianMixture(n_components=2, covariance_type='diag').fit(data)\n",
        "    gmm_classifiers[label] = gmm\n",
        "\n",
        "# (d & e) Compute accuracy\n",
        "def classify(image):\n",
        "    scores = []\n",
        "    for label, gmm in gmm_classifiers.items():\n",
        "        score = np.log((train_labels == label).mean()) + gmm.score_samples([image])\n",
        "        scores.append(score)\n",
        "    return np.argmax(scores)\n",
        "\n",
        "predicted_train_labels = [classify(img) for img in train_images]\n",
        "predicted_test_labels = [classify(img) for img in test_images]\n",
        "\n",
        "train_accuracy = accuracy_score(train_labels, predicted_train_labels)\n",
        "test_accuracy = accuracy_score(test_labels, predicted_test_labels)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing accuracy: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for mean, covariance, and priors for each class\n",
        "means = np.zeros((10, 28*28))\n",
        "covariances = np.zeros((10, 28*28))\n",
        "priors = np.zeros(10)\n",
        "\n",
        "# Estimate mean, covariance, and prior for each class\n",
        "for digit in range(10):\n",
        "    images_of_digit = train_images[train_labels == digit]\n",
        "    means[digit, :] = np.mean(images_of_digit, axis=0)\n",
        "    covariances[digit, :] = np.var(images_of_digit, axis=0) + 1e-6  # Adding small constant for stability\n",
        "    priors[digit] = len(images_of_digit) / len(train_images)\n",
        "\n",
        "def bayesian_classifier(x):\n",
        "    \"\"\"Classify an image using Bayes' rule.\"\"\"\n",
        "    posteriors = np.zeros(10)\n",
        "    for digit in range(10):\n",
        "        likelihood = np.exp(-0.5 * np.sum(((x - means[digit]) ** 2) / covariances[digit]))\n",
        "        posteriors[digit] = likelihood * priors[digit]\n",
        "    return np.argmax(posteriors)\n",
        "\n",
        "# Classify test images\n",
        "predicted_labels = np.array([bayesian_classifier(x) for x in test_images])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(predicted_labels == test_labels)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVE5RNlTzs2e",
        "outputId": "1df90e55-b5bc-4ef8-8db4-b4b691767f04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 9.80%\n"
          ]
        }
      ]
    }
  ]
}